# âš–ï¸ Multi-Task Legal Judgment Prediction

> åŸºäºŽ **Transformers + PyTorch** çš„å¤šä»»åŠ¡æ³•å¾‹åˆ¤å†³é¢„æµ‹ç³»ç»Ÿ  
> åŒ…å« **ç½ªåé¢„æµ‹ã€æ³•æ¡é¢„æµ‹ã€åˆ‘æœŸé¢„æµ‹** ä¸‰ä¸ªå­ä»»åŠ¡ï¼Œé€šè¿‡å¤šä»»åŠ¡å­¦ä¹ æå‡æ¨¡åž‹æ•ˆæžœã€‚  

[![Python](https://img.shields.io/badge/Python-3.9+-blue?logo=python)]()  
[![PyTorch](https://img.shields.io/badge/PyTorch-DeepLearning-red?logo=pytorch)]()  
[![Transformers](https://img.shields.io/badge/Transformers-HuggingFace-yellow?logo=huggingface)]()  
[![Wandb](https://img.shields.io/badge/Weights&Biases-Experiment_Tracking-orange?logo=weightsandbiases)]()  

---

## âœ¨ é¡¹ç›®äº®ç‚¹

- ðŸ› **å¤šä»»åŠ¡å­¦ä¹ **ï¼šå…±äº« Transformer ä¸»å¹²ï¼Œè®¾è®¡ä¸‰å¥—åˆ†ç±»å¤´  
  - ç½ªåé¢„æµ‹ï¼ˆå¤šæ ‡ç­¾åˆ†ç±»ï¼‰  
  - æ³•æ¡é¢„æµ‹ï¼ˆå¤šæ ‡ç­¾åˆ†ç±»ï¼‰  
  - åˆ‘æœŸé¢„æµ‹ï¼ˆå¤šç±»åˆ«åˆ†ç±»ï¼‰  
- ðŸ“Š **è¯„ä¼°æŒ‡æ ‡**ï¼šF1-macroï¼ˆç½ªå/æ³•æ¡ï¼‰ã€Accuracyï¼ˆåˆ‘æœŸï¼‰  
- âš¡ **å·¥ç¨‹å®žè·µ**ï¼š  
  - HuggingFace `Trainer` + è‡ªå®šä¹‰ `MultiTaskTrainer`  
  - `BCEWithLogitsLoss` + `CrossEntropyLoss` ç»„åˆæŸå¤±  
  - `EarlyStoppingCallback` æ—©åœæœºåˆ¶  
  - W&B å®žéªŒç®¡ç†  
- ðŸ“‚ **æ•°æ®å¤„ç†**ï¼šæ”¯æŒ JSONL æ ¼å¼ï¼Œè‡ªåŠ¨æž„å»º `DatasetDict`ï¼Œå¤šä»»åŠ¡æ ‡ç­¾å¤„ç†  

---

## ðŸ›  æŠ€æœ¯æ ˆ

- **è¯­è¨€**ï¼šPython 3.9+  
- **æ¡†æž¶**ï¼šPyTorch, HuggingFace Transformers  
- **è®­ç»ƒå·¥å…·**ï¼šAccelerate, Wandb, Trainer API  
- **æ•°æ®**ï¼šæ³•æ¡ã€ç½ªåã€åˆ‘æœŸæ ‡ç­¾ï¼ˆå¤šä»»åŠ¡ç›‘ç£ï¼‰  

---

## ðŸ“‚ é¡¹ç›®ç»“æž„

```bash
â”œâ”€â”€ data/                  # æ•°æ®é›† (train/test/labels)
â”œâ”€â”€ model.py               # æ¨¡åž‹å®šä¹‰ (MultiTaskLegalModel)
â”œâ”€â”€ trainer.py             # è‡ªå®šä¹‰ Trainer & è®­ç»ƒé€»è¾‘
â”œâ”€â”€ preprocess.py          # æ•°æ®åŠ è½½ä¸Žé¢„å¤„ç†
â”œâ”€â”€ inference.py           # æŽ¨ç†ä¸Žç»“æžœè¾“å‡º
â”œâ”€â”€ requirements.txt       # ä¾èµ–
â””â”€â”€ README.md              # é¡¹ç›®è¯´æ˜Ž
```
---

## ðŸš€ å¿«é€Ÿå¼€å§‹

bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/your-repo/legal-judgment-prediction.git
cd legal-judgment-prediction

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# è¿è¡Œè®­ç»ƒ
python trainer.py

# æŽ¨ç†é¢„æµ‹
python inference.py


æ³¨ï¼šå®žéªŒåŸºäºŽ hfl/chinese-roberta-wwm-ext-large

---


## ðŸ”® æ”¹è¿›æ–¹å‘


- å¼•å…¥ å¯¹æ¯”å­¦ä¹  æå‡è¡¨å¾èƒ½åŠ›
- ä½¿ç”¨ çŸ¥è¯†è’¸é¦ åŽ‹ç¼©å¤§æ¨¡åž‹
- éƒ¨ç½²è‡³ FastAPI / Gradio Web Demo
- å°è¯• RAG + æ³•å¾‹çŸ¥è¯†åº“ æå‡è§£é‡Šæ€§

---


## ðŸ”Ž æ¨¡åž‹æµç¨‹å›¾

```mermaid
graph TD
    A[è¾“å…¥: æ¡ˆä»¶æ–‡æœ¬] --> B[Transformer Encoder]
    B --> C1[ç½ªåé¢„æµ‹ Head]
    B --> C2[æ³•æ¡é¢„æµ‹ Head]
    B --> C3[åˆ‘æœŸé¢„æµ‹ Head]

    C1 --> D1[Macro F1]
    C2 --> D2[Macro F1]
    C3 --> D3[Accuracy]
